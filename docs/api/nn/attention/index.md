# torchmil.nn.attention

- [Attention Pool](attention_pool.md)
- [Multihead Self-Attention](multihead_self_attention.md)
- [Multihead Self-Attention with Relative Positional Encoding](rpe_multihead_self_attention.md)
- [Nystrom Self-Attention](nystrom_self_attention.md)
- [Multihead Cross-Attention](multihead_cross_attention.md)
