# RPE Multihead Self-Attention
::: torchmil.nn.attention.RPEMultiheadSelfAttention
    options:
        members:
            - __init__
            - forward