# torchmil.nn

## Available modules
- [Attention Pooling](attention_pool.md)
- [Multihead Self-Attention](multihead_self_attention.md)
- [Sm operator](sm.md)
- [Transformer](transformers/index.md)