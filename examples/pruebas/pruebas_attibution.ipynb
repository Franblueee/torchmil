{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "def constant(obj):\n",
    "    '''Wrapper function to create a function which returns a constant object regardless of arguments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : object\n",
    "        Constant object which the returned wrapper function will return on call.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wrapped_const : function\n",
    "        Function which when called with any arguments will return ``obj``.\n",
    "\n",
    "    '''\n",
    "    def wrapped_const(*args, **kwargs):\n",
    "        return obj\n",
    "    return wrapped_const\n",
    "\n",
    "\n",
    "def identity(obj):\n",
    "    '''Identity function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : object\n",
    "        Any object which will be returned.\n",
    "\n",
    "    Result\n",
    "    ------\n",
    "    obj : object\n",
    "        The original input argument ``obj``.\n",
    "\n",
    "    '''\n",
    "    return obj\n",
    "\n",
    "class Attributor(metaclass=ABCMeta):\n",
    "    '''Base Attributor Class.\n",
    "\n",
    "    Attributors are convenience objects with an optional composite and when called, compute an attribution, e.g., the\n",
    "    gradient or anything that is the result of computing the gradient when using the provided composite.  Attributors\n",
    "    also provide a context to be used in a `with` statement, similar to `CompositeContext`s. If the forward function\n",
    "    (or `self.__call__`) is called and the composite has not been registered (i.e. `composite.handles` is empty), the\n",
    "    composite will be temporarily registered to the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: :py:obj:`torch.nn.Module`\n",
    "        The model for which the attribution will be computed. If `composite` is provided, this will also be the model\n",
    "        to which the composite will be registered within `with` statements, or when calling the `Attributor` instance.\n",
    "    composite: :py:obj:`zennit.core.Composite`, optional\n",
    "        The optional composite to, if provided, be registered to the model within `with` statements or when calling the\n",
    "        `Attributor` instance.\n",
    "    attr_output: :py:obj:`torch.Tensor` or callable, optional\n",
    "        The default output attribution to be used when calling the `Attributor` instance, which is either a Tensor\n",
    "        compatible with any input used, or a function of the model's output. If None (default), the value will be the\n",
    "        identity function.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, model, composite=None, attr_output=None):\n",
    "        self.model = model\n",
    "        self.composite = composite\n",
    "\n",
    "        if attr_output is None:\n",
    "            self.attr_output_fn = identity\n",
    "        elif not callable(attr_output):\n",
    "            self.attr_output_fn = constant(attr_output)\n",
    "        else:\n",
    "            self.attr_output_fn = attr_output\n",
    "\n",
    "    def __enter__(self):\n",
    "        '''Register the composite, if provided.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: :py:obj:`Attributor`\n",
    "            The `Attributor` instance.\n",
    "\n",
    "        '''\n",
    "        if self.composite is not None:\n",
    "            self.composite.register(self.model)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        '''Remove the composite, if provided.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        False\n",
    "\n",
    "        '''\n",
    "        if self.composite is not None:\n",
    "            self.composite.remove()\n",
    "        return False\n",
    "\n",
    "    def __call__(self, input, attr_output=None):\n",
    "        '''Compute the attribution of the model wrt. `input`, using `attr_output` as the output attribution if\n",
    "        provided, or the default output attribution otherwise (if not supplied during instantiation either, this will\n",
    "        be the full output of the model). If a composite was supplied to the `Attributor` instance, but it was not yet\n",
    "        registered (either manually, or in a `with` statement), it will be registered to the model temporarily during\n",
    "        the call.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input: :py:obj:`torch.Tensor`\n",
    "            Input for the model, and wrt. compute the attribution\n",
    "        attr_output: :py:obj:`torch.Tensor` or callable, optional\n",
    "            The output attribution, which is either a Tensor compatible `input` (i.e. has the same shape as the output\n",
    "            of the model), or a function of the model's output. If None (default), the default attribution will be\n",
    "            used, which if neither supplied, will result in the model output used as the output attribution.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        output: :py:obj:`torch.Tensor`\n",
    "            Output of the model with argument `input`.\n",
    "        attribution: :py:obj:`torch.Tensor`\n",
    "            Attribution of the model wrt. to `input`, with the same shape as `input`.\n",
    "        '''\n",
    "        if attr_output is None:\n",
    "            attr_output_fn = self.attr_output_fn\n",
    "        elif not callable(attr_output):\n",
    "            attr_output_fn = constant(attr_output)\n",
    "        else:\n",
    "            attr_output_fn = attr_output\n",
    "\n",
    "        if self.composite is None or self.composite.handles:\n",
    "            return self.forward(input, attr_output_fn)\n",
    "\n",
    "        with self:\n",
    "            return self.forward(input, attr_output_fn)\n",
    "\n",
    "    @property\n",
    "    def inactive(self):\n",
    "        '''Return the attributor's composite's ``.inactive`` context.'''\n",
    "        return self.composite.inactive\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, input, attr_output_fn):\n",
    "        '''Abstract method. Compute the attribution of the model wrt. input, by using `attr_output_fn` as the function\n",
    "        of the model output to provide the output attribution. This function will not register the composite, and is\n",
    "        wrapped in the `__call__` of `Attributor`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input: :py:obj:`torch.Tensor`\n",
    "            Input for the model, and wrt. compute the attribution\n",
    "        attr_output: :py:obj:`torch.Tensor` or callable, optional\n",
    "            The output attribution function of the model's output.\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GradientTimesInput(Attributor):\n",
    "    '''Model-agnostic gradient times input.'''\n",
    "    def forward(self, input, attr_output_fn):\n",
    "        '''Compute gradient times input.'''\n",
    "        input_detached = input.detach().requires_grad_(True)\n",
    "        output = self.model(input_detached)\n",
    "        gradient, = torch.autograd.grad(\n",
    "            (output,), (input_detached,), (attr_output_fn(output.detach()),)\n",
    "        )\n",
    "        print(gradient.shape)\n",
    "        relevance = gradient * input\n",
    "        return output, relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(10, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "input = torch.randn(batch_size, 10)\n",
    "attr = GradientTimesInput(model)\n",
    "\n",
    "output, relevance = attr(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import weakref\n",
    "\n",
    "class RemovableHandle:\n",
    "    '''Create weak reference to call .remove on some instance.'''\n",
    "    def __init__(self, instance):\n",
    "        self.instance_ref = weakref.ref(instance)\n",
    "\n",
    "    def remove(self):\n",
    "        '''Call remove on weakly reference instance if it still exists.'''\n",
    "        instance = self.instance_ref()\n",
    "        if instance is not None:\n",
    "            instance.remove()\n",
    "\n",
    "\n",
    "class RemovableHandleList(list):\n",
    "    '''A list to hold handles, with the ability to call remove on all of its members.'''\n",
    "    def remove(self):\n",
    "        '''Call remove on all members, effectively removing handles from modules, or reverting canonizers.'''\n",
    "        for handle in self:\n",
    "            handle.remove()\n",
    "        self.clear()\n",
    "\n",
    "class CompositeContext:\n",
    "    '''A context object to register a composite in a context and remove the associated hooks and canonizers afterwards.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    module: :py:class:`torch.nn.Module`\n",
    "        The module to which `composite` should be registered.\n",
    "    composite: :py:class:`zennit.core.Composite`\n",
    "        The composite which shall be registered to `module`.\n",
    "    '''\n",
    "    def __init__(self, module, composite):\n",
    "        self.module = module\n",
    "        self.composite = composite\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.composite.register(self.module)\n",
    "        return self.module\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.composite.remove()\n",
    "        return False\n",
    "\n",
    "class Composite:\n",
    "    '''A Composite to apply canonizers and register hooks to modules.\n",
    "    One Composite instance may only be applied to a single module at a time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    module_map: callable, optional\n",
    "        A function ``(ctx: dict, name: str, module: torch.nn.Module) -> Hook or None`` which maps a context, name and\n",
    "        module to a matching :py:class:`~zennit.core.Hook`, or ``None`` if there is no matchin\n",
    "        :py:class:`~zennit.core.Hook`.\n",
    "    canonizers: list[:py:class:`zennit.canonizers.Canonizer`], optional\n",
    "        List of canonizer instances to be applied before applying hooks.\n",
    "    '''\n",
    "    def __init__(self, module_map=None, canonizers=None):\n",
    "        if module_map is None:\n",
    "            module_map = self._empty_module_map\n",
    "        if canonizers is None:\n",
    "            canonizers = []\n",
    "\n",
    "        self.module_map = module_map\n",
    "        self.canonizers = canonizers\n",
    "\n",
    "        self.handles = RemovableHandleList()\n",
    "        self.hook_refs = weakref.WeakSet()\n",
    "\n",
    "    def register(self, module):\n",
    "        '''Apply all canonizers and register all hooks to a module (and its recursive children).\n",
    "        Previous canonizers of this composite are reverted and all hooks registered by this composite are removed.\n",
    "        The module or any of its children (recursively) may still have other hooks attached.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        module: :py:class:`torch.nn.Module`\n",
    "            Hooks and canonizers will be applied to this module recursively according to ``module_map`` and\n",
    "            ``canonizers``.\n",
    "        '''\n",
    "        self.remove()\n",
    "\n",
    "        for canonizer in self.canonizers:\n",
    "            self.handles += canonizer.apply(module)\n",
    "\n",
    "        ctx = {}\n",
    "        for name, child in module.named_modules():\n",
    "            template = self.module_map(ctx, name, child)\n",
    "            if template is not None:\n",
    "                hook = template.copy()\n",
    "                self.hook_refs.add(hook)\n",
    "                self.handles.append(hook.register(child))\n",
    "\n",
    "    def remove(self):\n",
    "        '''Remove all handles for hooks and canonizers.\n",
    "        Hooks will simply be removed from their corresponding Modules.\n",
    "        Canonizers will revert the state of the modules they changed.\n",
    "        '''\n",
    "        self.handles.remove()\n",
    "        self.hook_refs.clear()\n",
    "\n",
    "    def context(self, module):\n",
    "        '''Return a CompositeContext object with this instance and the supplied module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        module: :py:class:`torch.nn.Module`\n",
    "            Module for which to register this composite in the context.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :py:class:`zennit.core.CompositeContext`\n",
    "            A context object which registers the composite to ``module`` on entering, and removes it on exiting.\n",
    "        '''\n",
    "        return CompositeContext(module, self)\n",
    "\n",
    "    @contextmanager\n",
    "    def inactive(self):\n",
    "        '''Context manager to temporarily deactivate the gradient modification. This can be used to compute the\n",
    "        gradient of the modified gradient.\n",
    "        '''\n",
    "        try:\n",
    "            for hook in self.hook_refs:\n",
    "                hook.active = False\n",
    "            yield self\n",
    "        finally:\n",
    "            for hook in self.hook_refs:\n",
    "                hook.active = True\n",
    "\n",
    "    @staticmethod\n",
    "    def _empty_module_map(ctx, name, module):\n",
    "        '''Empty module_map, does not assign any rules.'''\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
