{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a MIL model for cancer detection in Whole Slide Images\n",
    "\n",
    "One of the applications of Multiple Instance Learning is the detection cancerous tissue in Whole Slide Images (WSIs). A WSis is obtained by \"digitally  converting a tissue on a glass slide into a high-resolution virtual slide\" ([NiH](https://pmc.ncbi.nlm.nih.gov/articles/PMC7522141/)). This slides are the size of gigapixels, which makes their computational treatment unfeasible. A possible solution for this problem is to divide the slide in <tt>patches</tt> and treat the patches individually. Thus, we may see a WSI as a bag, where each patch is an instance, which sets us up in the Multiple Instance Learning scenario.  \n",
    "\n",
    "In the following, we explain how to train a Multiple Instance Learning (MIL) model to detect cancerous WSIs and localize the cancerous tissue using the <tt>torchmil</tt> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../torchmil/')\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "!!! example \"MIL binary classification\"\n",
    "    In this case, the bags have the form $\\mathbf{X} = \\left[ \\mathbf{x}_1, \\ldots, \\mathbf{x}_N \\right]^\\top \\in \\mathbb{R}^{N \\times D}$, where each $\\mathbf{x}_n \\in \\mathbb{R}^D$ is an instance. \n",
    "    The labels of the instances are $\\mathbf{y} = \\left[ y_1, \\ldots, y_N \\right]^\\top \\in \\{0, 1\\}^N$, but we do not have access to them at training time (they may be accessible at test time). The label of the bag is $Y \\in \\{0, 1\\}$, and the relation between the instance labels and the bag label is as follows:\n",
    "\n",
    "    $$ Y = \\max \\left\\{ y_1, \\ldots, y_N \\right\\} $$\n",
    "\n",
    "    This example is the most common in MIL, but there are many other possibilities. \n",
    "\n",
    "For this tutorial, we will use the Camelyon16 dataset, a public dataset for the detection of breast cancer metastasis. The [original version](https://camelyon17.grand-challenge.org/Data/) of this dataset has been processed to be used for MIL binary classification problems. It can be downloaded from [here](https://huggingface.co/datasets/Franblueee/Camelyon16_MIL/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, training a MIL model directly on the slices is computationally intractable. Due to this limitation, MIL models usually operate on pre-computed features extracted from each of the instances. Although <tt>torchmil</tt> allows to define models that receive the original slices as input, in this tutorial we will use the pre-computed features since it is the most common form of alleviating this computational barrier. We have processed the CAMELYON16 dataset to be used for MIL binary classification problems. It can be downloaded from [here](https://huggingface.co/datasets/Franblueee/Camelyon16_MIL/). To facilitate your MIL tasks, we have extracted the features of all the patches using <tt>Resnet50</tt> trained with self-supervised learning ([Barlow Twins method](https://arxiv.org/abs/2103.03230)) and the **foundation model** <tt>UNI</tt> (check this very cool model [here](https://huggingface.co/MahmoodLab/UNI)).\n",
    "\n",
    "We now make use of `torchmil.datasets.CAMELYON16MILDataset` to create an object that serves as a `torch.utils.data.Dataset` dataset and contains RSNA. You only need to provide the `root` to the processed dataset, the `patch_size`, the desired feature extractor (`features`) and the `partition`. Also, when using <tt>WSI</tt> datasets, you may be interesed in the relative positioning of the patches. While loading the dataset, <tt>torchmil</tt> loads the adjacency matrix and offers two additional parameters that may be used to refine that matrix: `adj_with_dist`, which builds the adjacency matrix is built using the Euclidean distance between the patches features, and `norm_adj` which normalizes the adjacency matrix. For this example we will omit the use of the adjacency matrix.\n",
    "\n",
    "See how simple is to instance the train dataset, using the <tt>UNI</tt> features and patches of size $512 \\times 512$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmil.datasets import CAMELYON16MILDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root = '/data/datasets/CAMELYON16/'\n",
    "features = 'UNI'\n",
    "patch_size = 512\n",
    "\n",
    "dataset        = CAMELYON16MILDataset(  root        = root,\n",
    "                                        features    = features,\n",
    "                                        patch_size  = patch_size,\n",
    "                                        partition   = 'train')\n",
    "            \n",
    "# Split the dataset into train and validation sets\n",
    "bag_labels = dataset.get_bag_labels()\n",
    "idx = list(range(len(bag_labels)))\n",
    "val_prop = 0.2\n",
    "idx_train, idx_val = train_test_split(idx, test_size=val_prop, random_state=1234, stratify=bag_labels)\n",
    "train_dataset = dataset.subset(idx_train)\n",
    "val_dataset = dataset.subset(idx_val)\n",
    "\n",
    "test_dataset   = CAMELYON16MILDataset( root        = root,\n",
    "                                       features    = features,\n",
    "                                       partition   = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In <tt>torchmil</tt>, each bag is a `TensorDict`. The different keys correspond to different elements of the bag. In this case, each bag has a feature matrix `X`, the bag label `Y`, and the instance labels `y_inst`. A patch is considered positive if at least $50\\%$ of its pixels are cancerous. Recall that the instance labels cannot be used during training, they are available only for evaluation purposes.\n",
    "\n",
    "## Mini-batching of bags\n",
    "\n",
    "Tipically, the bags in a MIL dataset have different size. This can be a problem when creating mini-batches. To solve this, we use the function `collate_fn` from the [<tt><b>torchmil.data</b></tt>](../api/data/index.md) module. This function creates a mini-batch of bags by padding the bags with zeros to the size of the largest bag in the batch. The function also returns a mask tensor that indicates which instances are real and which are padding.\n",
    "\n",
    "!!! question \"Why not use [`torch.nested`](https://pytorch.org/docs/stable/nested.html)?\"\n",
    "    `torch.nested` offer a more flexible method for handling bags of varying sizes. However, since the PyTorch API for nested tensors is still in the prototype stage, <tt><b>torchmil</b></tt> currently relies on the padding approach.\n",
    "\n",
    "Let's create the dataloaders and visualize the shape of a mini-batch. When using a patch size of $512 \\times 512$, some of the bags in CAMELYON16 produce more than $20.000$ instances. Because of this, we need to use a small `batch_size` to be able to fit it in standard <tt>GPUs</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape:  torch.Size([4, 29946, 1024])\n",
      "Batch Y shape:  torch.Size([4])\n",
      "Batch y_inst shape:  torch.Size([4, 29946])\n",
      "Batch mask shape:  torch.Size([4, 29946])\n"
     ]
    }
   ],
   "source": [
    "from torchmil.data import collate_fn\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "data_shape = (batch['X'].shape[-1], )\n",
    "print(\"Batch X shape: \", batch['X'].shape)\n",
    "print(\"Batch Y shape: \", batch['Y'].shape)\n",
    "print(\"Batch y_inst shape: \", batch['y_inst'].shape)\n",
    "print(\"Batch mask shape: \", batch['mask'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch is again a `TensorDict` with an additional key `mask` that indicates which instances are real and which are padding. As we can see, the bags are padded to the maximum size of the bags in the batch with zeros. The mask tensor indicates which elements are real instances and which are padding. The function `collate_fn` also pads other tensors, such as the adjacency matrix or the instance coordinates. \n",
    "\n",
    "## Training a model in CAMELYON16\n",
    "\n",
    "We have shown how to load the CAMELYON16 dataset for the binary classification task. Now, let us train a MIL model in this dataset! For this example, we will use <tt>torchmil</tt> implementation of a [Transformer ABMIL](../api/models/transformer_abmil.md), a version of [ABMIL](../api/models/abmil.md) where a [Transformer Encoder](../api/nn/transformers/conventional_transformer.md) is applied to refine the instances before the [Attention Pool](../api/nn/attention/attention_pool.md). To highlight how simple is to instance a model in <tt>torchmil</tt>, we will leave all the parameters by default except for the `in_shape`, which reflects the data shape. Feel free to check the [documentation of Transformer ABMIL](../api/models/transformer_abmil.md) to observe the different parameters that this model can be passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmil.models import TransformerABMIL\n",
    "model = TransformerABMIL( in_shape = data_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? It can not be easier! Now, let's train the model. <tt>torchmil</tt> offers an easy-to-use trainer class located in `torchmil.utils.trainer.Trainer` that provides a generic training for any MIL model. Also, it will show the evolution of the losses and the desired metrics during the epochs.\n",
    "\n",
    "!!! note\n",
    "    This `Trainer` gives the flexibility to log the results using any wrapped `logger`, use annealing for the loss functions via the `annealing_scheduler_dict` dictionary, or to set a learning rate scheduler using the parameter `lr_scheduler`. Also, you can follow multiple metrics during the training thanks to the parameter `metrics_dict` and the integration with the <tt>torchmetrics</tt> package.\n",
    "\n",
    "For now, let us just keep it simple and perform a simple training using the `torch.optim.Adam` optimizer. When using the features from the <tt>UNI</tt> model, <tt>torchmil</tt> models obtain very good results in just a few epochs. We will train the model for only 2 epochs. First, we instance the trainer and then we train the model. We hide the output of the training using `verbose = False` and we disable progress bars using `disable_pbar = True`.\n",
    "\n",
    "!!! note\n",
    "    Transformers are computationally expensive models, so training this model for two epochs takes approximately `20` minutes in our <tt>CPUs</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmil.utils.trainer import Trainer\n",
    "import torchmetrics\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = 'cpu'\n",
    "\n",
    "trainer = Trainer(  model        = model,\n",
    "                    optimizer    = optimizer,\n",
    "                    metrics_dict = {'auroc' : torchmetrics.AUROC(task='binary').to(device), 'acc': torchmetrics.Accuracy(task='binary').to(device)},\n",
    "                    obj_metric   = 'acc',\n",
    "                    device       = device,\n",
    "                    disable_pbar = True,\n",
    "                    verbose      = False, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_017. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_030. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_070. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_010. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_059. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_008. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_040. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_067. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag tumor_035. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag test_097. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag test_116. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag test_099. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag test_013. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag test_011. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n",
      "/work/work_fjaviersaezm/torchmil/examples/../../torchmil/torchmil/datasets/binary_classification_dataset.py:61: UserWarning: Instance labels are not consistent with bag label for bag test_004. Setting all instance labels to the bag label.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "trainer.train( max_epochs       = EPOCHS,\n",
    "               train_dataloader = train_dataloader,\n",
    "               val_dataloader   = val_dataloader,\n",
    "               test_dataloader  = test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! question \"Why is the first epoch much slower?\"\n",
    "    If you set `disable_pbar = False`, you may observe that the first epoch is much slower than the rest of them. The first time the dataloader indexes a bag, that bag is loaded from a <tt>.npy</tt> file. Thus, if the data is not used before the training, during the first epoch the bags are loaded from the hard drive to the computer's memory, causing a delay in the training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model. We are going to compute the accuracy and f1-score on the test set. The accuracy is the proportion of correctly classified bags, while the f1-score is the harmonic mean of precision and recall. The f1-score is a good metric for imbalanced datasets.\n",
    "Typically, in MIL datasets, there are many more negative instances than positive instances. In this case, the f1-score will be very useful.\n",
    "\n",
    "First, we define some auxiliary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, y):\n",
    "    return (pred == y).sum().item() / len(y)\n",
    "\n",
    "def f1_score(pred, y):\n",
    "    tp = ((pred == 1) & (y == 1)).sum().item()\n",
    "    fp = ((pred == 1) & (y == 0)).sum().item()\n",
    "    fn = ((pred == 0) & (y == 1)).sum().item()\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute we can easily obtain the model's performance in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/bag/acc: 0.9612403100775194\n",
      "test/bag/f1: 0.9462360402361285\n"
     ]
    }
   ],
   "source": [
    "inst_pred_list = []\n",
    "y_inst_list = []\n",
    "Y_pred_list = []\n",
    "Y_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    # predict bag label using our model\n",
    "    out = model(batch['X'], batch['mask'])\n",
    "    Y_pred = (out > 0).float()\n",
    "\n",
    "    Y_pred_list.append(Y_pred)\n",
    "    Y_list.append(batch['Y'])\n",
    "\n",
    "Y_pred = torch.cat(Y_pred_list)\n",
    "Y = torch.cat(Y_list)\n",
    "\n",
    "print(f\"test/bag/acc: {accuracy(Y_pred, Y)}\")\n",
    "print(f\"test/bag/f1: {f1_score(Y_pred, Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Our model has reached a very high accuracy and f1-score in only 2 epochs! This shows how simple is to obtain very good results in one of the most famous <tt>WSI</tt> classification dataset, such as <tt>Camelyon16</tt>, thanks to <tt>torchmil</tt>!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
