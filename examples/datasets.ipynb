{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "When implementing a MIL model, the first step is to define a `MILDataset` to apply the model. In this tutorial, we will show how MIL datasets are implemented in <tt>torchmil</tt>.\n",
    "\n",
    "## Required data and hard drive organization\n",
    "\n",
    "In a <tt>torchmil</tt> dataset, each bag is composed of four elements:\n",
    "\n",
    "- `features`: with shape `(bag_size, feature_dim)` with the features of the bag. Usually, the `features` will be the result of applying a feature extractor to the patches of the slide.\n",
    "- `label`: with shape `()`, containing the bag label.\n",
    "- `patch_labels`: with shape `(bag_size, )`, containing the label of the instance.\n",
    "- `coords`: with shape `(bag_size, coords_dim)`, containing the coordinates of each of the patches in the bag. \n",
    "\n",
    "!!! note \"Not everything is required\"\n",
    "    Even though the implementation manages `features, labels, patch_labels` and `coords`, they are not strictly required to build a dataset. For instance, if the `patch_labels`, the dataset can still be used with the rest of the elements.\n",
    "    \n",
    "\n",
    "The first step is to organize the files in our system in a way that is compatible with the implementation of the `ProcessedMILDataset`, which is the base class used to implement new datasets. One folder is required for each of the required elements. Assuming that the patches have the size `patch_size` and that the features were extracted using `feature_extractor`, the following folder structure is required:\n",
    "```\n",
    "{dataset_name}\n",
    "├── patches_{patch_size}\n",
    "│   ├── features\n",
    "│   │   ├── features_{feature_extractor}\n",
    "│   │   │   ├── bag1.npy\n",
    "│   │   │   ├── bag2.npy\n",
    "│   │   │   └── ...\n",
    "│   ├── labels\n",
    "│   │   ├── bag1.npy\n",
    "│   │   ├── bag2.npy\n",
    "│   │   └── ...\n",
    "│   ├── patch_labels\n",
    "│   │   ├── bag1.npy\n",
    "│   │   ├── bag2.npy\n",
    "│   │   └── ...\n",
    "│   ├── coords\n",
    "│   │   ├── bag1.npy\n",
    "│   │   ├── bag2.npy\n",
    "│   │   └── ...\n",
    "```\n",
    "\n",
    "!!! important\n",
    "    As the folder structure shows, there must exist one folder for each required type of element (`features, labels, patch_labels, coords`), and one `.npy` file per element. Each `.npy` file must be named as the bag that it represents. \n",
    "\n",
    "## The `ProcessedMILDataset` class\n",
    "\n",
    "The `ProcessedMILDataset` class manages the bag loading and adjacency matrix building (if `coords` are available). To initialize this class only 2 parameters are required: `features_path` and `labels_path`, indicating the path to the respective folders. However, using also `inst_labels_path`, `coords_path` (both indicating paths), and `bag_names` (containing a list of all the bag names in the dataset) is recommended. Another important parameter is `bag_keys`, which indicates which elements the `__get_item__` function will return, defaulting to all the options: `[\"X\", \"Y\", \"y_inst\", \"adj\", \"coords\"]`.\n",
    "\n",
    "!!! note \"First time loading the data in an execution\"\n",
    "    The `ProcessedMILDataset` class has an extra parameter `load_at_init` which defaults to `True`. With this option, the data is loaded to cache when the dataset is instantiated. Changing this parameter to `load_at_init=False` implies that the data is not read until it is required by the `__get_item__` function.\n",
    "\n",
    "The adjacency matrix `adj` of each bag is created when each bag is built (i.e., when it is loaded for the first time). Some options can be passed to obtain different versions of `adj`. Feel free to see the options in the documentation of [<tt><b>torchmil.datasets.processed_mil_dataset</b></tt>](../api/datasets/processed_mil_dataset.md).\n",
    "\n",
    "### Extending `ProcessedMILDataset` funcionalities.\n",
    "\n",
    "As an additional feature, <tt>torchmil</tt> implements `BinaryClassificationDataset`, a subclass of `ProcessedMILDataset`. This subclass assumes that\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "        Y \\in \\left\\{ 0, 1 \\right\\}, \\quad y_n \\in \\left\\{ 0, 1 \\right\\}, \\quad \\forall n \\in \\left\\{ 1, \\ldots, N \\right\\},\\\\\n",
    "        Y = \\max \\left\\{ y_1, \\ldots, y_N \\right\\}.\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "The functionality of this class extends `ProcessedMILDataset` by adding explicit comprobations to ensure that the conditions in equations are fullfilled. If they are not, a warning is shown on the output stream. Check all the information about this class in [<tt><b>torchmil.datasets.binary_classification_dataset</b></tt>](../api/datasets/binary_classification_dataset.md).\n",
    "\n",
    "\n",
    "Also, the class `WSIDataset` assumes that the bags are Whole Slide Images (WSIs), and it gives the coordinates of the patches (`coords`) a special treatment, normalizing their values. Find more information about this class in [<tt><b>torchmil.datasets.wsi_dataset</b></tt>](../api/datasets/wsi_dataset.md).\n",
    "\n",
    "\n",
    "## Creating your own dataset\n",
    "\n",
    "With the provided explanation, we are now ready to define a custom class to use <tt>torchmil</tt> in your own dataset. We will implement a WSI dataset using slides from the [Genotype-Tissue Expression (GTEx) Project](https://www.gtexportal.org/home/), which can be downloaded for free. Particularly, we will use slides of <tt>UrinaryBladder</tt> tissue. \n",
    "\n",
    "To create the dataset, we must first extract the `coords` of the patches from the original <tt>.tiff</tt> files and then extract `features` from those patches. To achieve that, a tool like [CLAM](https://github.com/mahmoodlab/CLAM) can be used. We will assume that no masks are provided, so we will not have access to `labels` or `inst_labels`. We have extracted the features using the foundation model [UNI](https://huggingface.co/MahmoodLab/UNI).\n",
    "\n",
    "Then, creating the dataset is as simple as defining a new class that extends `WSIDataset` and properly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchmil.datasets import WSIDataset\n",
    "from torchmil.utils.common import read_csv, keep_only_existing_files\n",
    "\n",
    "\n",
    "class GTExUrinaryBladderDataset(WSIDataset):\n",
    "    r\"\"\"\n",
    "\n",
    "    GTEx Urinary Bladder dataset.\n",
    "    This dataset is an example of dataset with no labels.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root : str,\n",
    "        features : str = 'UNI',\n",
    "        partition : str = 'train',\n",
    "        bag_keys: list = [\"X\", \"Y\", \"y_inst\", \"adj\", \"coords\"],\n",
    "        patch_size: int = 512,\n",
    "        adj_with_dist: bool = False,\n",
    "        norm_adj: bool = True,\n",
    "        load_at_init: bool = True\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            root: Path to the root directory of the dataset.\n",
    "            features: Type of features to use. Must be one of ['UNI'].\n",
    "            partition: Partition of the dataset. Must be one of ['train', 'test'].\n",
    "            bag_keys: List of keys to use for the bags. Must be in ['X', 'Y', 'y_inst', 'coords'].\n",
    "            patch_size: Size of the patches. Currently, only 512 is supported.\n",
    "            adj_with_dist: If True, the adjacency matrix is built using the Euclidean distance between the patches features. If False, the adjacency matrix is binary.\n",
    "            norm_adj: If True, normalize the adjacency matrix.\n",
    "            load_at_init: If True, load the bags at initialization. If False, load the bags on demand.\n",
    "        \"\"\"\n",
    "\n",
    "        features_path = f'{root}/patches_{patch_size}/features/features_{features}/'\n",
    "        labels_path = f'{root}/patches_{patch_size}/labels/'\n",
    "        patch_labels_path = f'{root}/patches_{patch_size}/inst_labels/'\n",
    "        coords_path = f'{root}/patches_{patch_size}/coords/'\n",
    "\n",
    "        # This csv is generated by CLAM, with slide_id containing \"bag_name.format\"\n",
    "        bag_names_file = f'{root}/patches_{patch_size}/process_list_autogen.csv'\n",
    "        dict_list = read_csv(bag_names_file)\n",
    "        wsi_names = list(set([ row['slide_id'].split('.')[0] for row in dict_list]))\n",
    "        wsi_names = keep_only_existing_files(features_path, wsi_names)\n",
    "\n",
    "        WSIDataset.__init__(\n",
    "            self,\n",
    "            features_path=features_path,\n",
    "            labels_path=labels_path,\n",
    "            patch_labels_path=patch_labels_path,\n",
    "            coords_path=coords_path,\n",
    "            wsi_names=wsi_names,\n",
    "            bag_keys=bag_keys,\n",
    "            patch_size=patch_size,\n",
    "            adj_with_dist=adj_with_dist,\n",
    "            norm_adj=norm_adj,\n",
    "            load_at_init=load_at_init\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now defined our new `GTExUrinaryBladderDataset` class. We can now instantiate it, using as `bag_keys` only the features `X` and the adjacency matrix `adj`.  We only have to specify the root path! We will use `load_at_init = False` so that the features of the slides are only loaded when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTEX-N7MS-2125', 'GTEX-N7MT-1825', 'GTEX-NFK9-2125', 'GTEX-NL3G-1925', 'GTEX-NL3H-2125', 'GTEX-NL4W-1125', 'GTEX-NPJ7-2625', 'GTEX-NPJ8-1125', 'GTEX-O5YT-1925', 'GTEX-O5YU-2125', 'GTEX-O5YV-2125', 'GTEX-OHPJ-1925', 'GTEX-OHPK-1925', 'GTEX-OHPL-1925', 'GTEX-OHPM-1925', 'GTEX-OHPN-1825', 'GTEX-OIZF-1925', 'GTEX-OIZG-1825', 'GTEX-OIZH-1925', 'GTEX-OIZI-1925', 'GTEX-OOBJ-1925', 'GTEX-OOBK-1925', 'GTEX-OXRK-1925', 'GTEX-OXRL-1925', 'GTEX-OXRN-2225', 'GTEX-OXRO-1125', 'GTEX-OXRP-1425', 'GTEX-P44G-2025', 'GTEX-P44H-2225', 'GTEX-P4PP-1925', 'GTEX-P4PQ-1925', 'GTEX-P4QR-2325', 'GTEX-P4QS-1925', 'GTEX-P4QT-1925', 'GTEX-P78B-2125', 'GTEX-PLZ4-2025', 'GTEX-PLZ5-1325', 'GTEX-PLZ6-1025', 'GTEX-POMQ-0925', 'GTEX-POYW-2225', 'GTEX-PSDG-2025', 'GTEX-PVOW-2425', 'GTEX-PW2O-1025', 'GTEX-PWCY-1125', 'GTEX-PWN1-1925', 'GTEX-PWO3-2725', 'GTEX-PWOO-1425', 'GTEX-PX3G-1925', 'GTEX-Q2AG-2125', 'GTEX-Q2AH-1325', 'GTEX-Q2AI-1025', 'GTEX-Q734-1225', 'GTEX-QCQG-0825', 'GTEX-QDT8-2825', 'GTEX-QDVJ-1525', 'GTEX-QDVN-1425', 'GTEX-QEG4-2125', 'GTEX-QEG5-2325', 'GTEX-QEL4-1825', 'GTEX-QESD-0925', 'GTEX-QLQ7-1225', 'GTEX-QLQW-0825', 'GTEX-QMR6-2525', 'GTEX-QMRM-1325', 'GTEX-QV31-0925', 'GTEX-QV44-1425', 'GTEX-QVJO-2625', 'GTEX-QVUS-2725', 'GTEX-QXCU-2225', 'GTEX-R3RS-2025', 'GTEX-R45C-2425', 'GTEX-R53T-1425', 'GTEX-R55C-1225', 'GTEX-R55D-1625', 'GTEX-R55E-2225', 'GTEX-R55F-0925', 'GTEX-R55G-1325', 'GTEX-REY6-2025', 'GTEX-RM2N-1025', 'GTEX-RN5K-2725', 'GTEX-RN64-2425', 'GTEX-RNOR-2125', 'GTEX-RTLS-2525', 'GTEX-RU1J-0725', 'GTEX-RU72-2525', 'GTEX-RUSQ-1325', 'GTEX-RVPU-1925', 'GTEX-RVPV-2425', 'GTEX-RWS6-1425', 'GTEX-RWSA-2125', 'GTEX-S32W-1125', 'GTEX-S33H-1925', 'GTEX-S341-0925', 'GTEX-S3LF-2125', 'GTEX-S3XE-1225', 'GTEX-S4P3-0825', 'GTEX-S4Q7-0925', 'GTEX-S4UY-0925', 'GTEX-S4Z8-1325', 'GTEX-S7PM-2325', 'GTEX-S7SE-2325', 'GTEX-S7SF-1125', 'GTEX-S95S-0625', 'GTEX-SE5C-1025', 'GTEX-SIU7-1025', 'GTEX-SIU8-2125', 'GTEX-SJXC-2125', 'GTEX-SN8G-2025', 'GTEX-SNMC-0825', 'GTEX-SNOS-0525', 'GTEX-SUCS-1225', 'GTEX-T2IS-2525', 'GTEX-T2YK-2325', 'GTEX-T5JC-1125', 'GTEX-T5JW-0625', 'GTEX-T5JW-1025', 'GTEX-T6MN-2225', 'GTEX-T6MO-0925', 'GTEX-TKQ1-0725', 'GTEX-TKQ2-0525', 'GTEX-TML8-0625', 'GTEX-TMMY-1525', 'GTEX-TSE9-2425', 'GTEX-U3ZH-0825', 'GTEX-U3ZM-0825', 'GTEX-U3ZN-1225', 'GTEX-U412-1925', 'GTEX-U4B1-1225', 'GTEX-U8T8-1525']\n"
     ]
    }
   ],
   "source": [
    "root = '/data/data_fjaviersaezm/GTExTorchmil/UrinaryBladder/'\n",
    "dataset = GTExUrinaryBladderDataset(root = root, partition='train', features='UNI', bag_keys=['X', 'y_inst', 'adj'], patch_size=512, adj_with_dist=False, norm_adj=True, load_at_init=False)\n",
    "print(dataset.bag_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! All the bags have been recognized. Now we can display a bag, which is returned as a `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/work_fjaviersaezm/torchmil/torchmil/datasets/processed_mil_dataset.py:164: UserWarning: Instance labels file /data/data_fjaviersaezm/GTExTorchmil/UrinaryBladder//patches_512/inst_labels/GTEX-N7MS-2125.npy not found. Setting instance labels to None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m el = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(el.keys())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(el[\u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m].shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/work_fjaviersaezm/torchmil/torchmil/datasets/processed_mil_dataset.py:309\u001b[39m, in \u001b[36mProcessedMILDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    307\u001b[39m     bag_dict = \u001b[38;5;28mself\u001b[39m.loaded_bags[bag_name]\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     bag_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_bag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbag_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m     \u001b[38;5;28mself\u001b[39m.loaded_bags[bag_name] = bag_dict\n\u001b[32m    312\u001b[39m return_bag_dict = {\n\u001b[32m    313\u001b[39m     key: bag_dict[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bag_keys \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m bag_dict\n\u001b[32m    314\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/work_fjaviersaezm/torchmil/torchmil/datasets/processed_mil_dataset.py:246\u001b[39m, in \u001b[36mProcessedMILDataset._build_bag\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my_inst\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m bag_dict:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m         bag_dict[key] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbag_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bag_dict\n",
      "\u001b[31mTypeError\u001b[39m: expected np.ndarray (got NoneType)"
     ]
    }
   ],
   "source": [
    "el = dataset[0]\n",
    "print(el.keys())\n",
    "print(el['X'].shape)\n",
    "print(el['adj'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, the dataset object printed a warning since it could not find the instance labels, but properly loaded the `features` of the bag and, using the `coords`, it built the adjacency matrix correctly. \n",
    "\n",
    "Building a new dataset for <tt>torchmil</tt> was super easy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
