# TODO list

- [ ] Index and introduction to the library.
- [ ] Tutorials:
    - [ X ] Tutorial 0: "Training your first MIL model": Training a simple ABMIL with a MNIST toy dataset
    - [ X ] Tutorial 1: "Data representation in torchmil": how to represent data in torchmil (bags, instances, graphs, mask, etc)
    - [ ] Tutorial 2: "Datasets in torchmil": how datasets are implemented in torchmil: processed datasets vs non-processed datasets. 
    - [ ] Tutorial 3: "WSI classification in torchmil": how to train a model with WSI data.
    - [ ] Tutorial 4: "CTScan classification in torchmil": how to train a model with CTScan data.
    - [ ] Tutorial 5: "Visualizing attention maps": how to visualize attention maps in torchmil.
    - [ ] Tutorial 6: (Advanced) "Integrating torchmil with Pytorch Geometric": how to use a module from Pytorch Geometric in torchmil.
- [ ] Tests
- Documentation:
    - torchmil.datasets:
        - [ X ] Processed MIL dataset
        - [ X ] WSI dataset
        - [ X ] CTScan dataset
        - [ X ] Toy dataset
        - [ X ] Datasets from: https://arxiv.org/abs/2310.17867
        - [   ] Camelyon16
        - [   ] PANDA   
        - [   ] RSNA_ICH
        - [ ] Allow datasets to be downloaded from the internet ?
    - torchmil.models:
        - [ X ] mil_model
        - [ ] Remove criterion from models ???
        - [ X ] ABMIL
        - [ X ] TransformerABMIL
        - [ X ] SmABMIL
        - [ X ] SmTransformerABMIL
        - [ X ] ProbSmoothABMIL
        - [ X ] ProbSmoothTransformerABMIL
        - [ X ] CLAM
            - [  ] Modify inst_eval, inst_eval_out so they accept batched inputs
        - [ X ] DSMIL
        - [ X ] DFTDMIL
        - [ X ] PatchGCN
            - [ ] Implement GENConv, right now PatchGCN uses GCNConv
        - [ X ] DeepGraphSurv
        - [ X ] TransMIL
        - [ X ] GTP
        - [ X ] CAMIL
        - [ X ] IIBMIL
        - [ X ] SETMIL
    - torchmil.nn:
        - [ ] attention
            - [ ] index
            - [ X ] attention_pool
            - [ X ] multihead_self_attention
            - [ X ] multihead_cross_attention
            - [ X ] nystr√∂m_attention
            - [ X ] prob_smooth_attention_pool
            - [ X ] irpe_multihead_self_attention
            - [ X ] sm_attention_pool
        - [ ] transformers
            - [ ] index
            - [ X ] encoder
            - [ X ] layer
            - [ X ] conventional_transformer
            - [ X ] nystrom_transformer
            - [ X ] irpe_transformer
            - [ X ] sm_transformer
            - [ X ] t2t
        - [ ] gnns
            - [ ] index
            - [ X ] deepgcn
            - [ X ] dense_mincut_pool
            - [ X ] gcn_conv
        - [ X ] sm
        - [ X ] utils
        - [ X ] max_pool
        - [ X ] mean_pool 
    - [ X ] visualize
    - [ ] utils
- [ ] Singleton dimension in bag labels
- [ ] Add support for Lazy initialization (remove the need to specify in_dim)
- [ ] Bag class or Tensordict (?)
- [ ] Integration with Pytorch geometric (?)
